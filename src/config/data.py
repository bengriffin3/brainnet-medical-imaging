# -*- coding: utf-8 -*-
"""data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xOBQejhp-1juIK1rbn5uUU87IWIXDU6q
"""

# Standard library imports
import os
import pathlib
from typing import Tuple, Dict, List

import kagglehub
import pandas as pd
import shutil
from tqdm import tqdm  # for progress bar (optional)
import hashlib

# PyTorch imports
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
from torch.optim.lr_scheduler import ReduceLROnPlateau

#Topo imports
import gudhi as gd
import PersistenceImages.persistence_images as pimg

from PIL import Image
import random
import matplotlib.pyplot as plt
import numpy as np

# Set up device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'Using device: {device}')

label_conversion_dict = {
            'glioma': 0,
            'meningioma': 1,
            'notumor': 2,
            'pituitary': 3,
            0: 'glioma',
            1: 'meningioma',
            2: 'notumor',
            3: 'pituitary'
        }

def data_setup(vision_transformer=False):
    # Download dataset (must be assigned or it won't persist)
    dataset_path = kagglehub.dataset_download("masoudnickparvar/brain-tumor-mri-dataset")

    # Create a directory for unique files
    new_path = '/tmp/unique_files/'
    os.makedirs(new_path, exist_ok=True)

    label_conversion_dict = {
        'glioma': 0,
        'meningioma': 1,
        'notumor': 2,
        'pituitary': 3,
        0: 'glioma',
        1: 'meningioma',
        2: 'notumor',
        3: 'pituitary'
    }

    # Collect all file paths in the dataset
    file_paths = []
    for root, _, files in os.walk(dataset_path):
        for file in files:
            file_paths.append(os.path.join(root, file))

    df = pd.DataFrame({'filepath': file_paths})
    df['filename'] = df['filepath'].apply(lambda x: os.path.basename(x))

    # Remove duplicates based on file content (hash)
    df['hash'] = df['filepath'].apply(lambda x: hashlib.md5(open(x, 'rb').read()).hexdigest())
    df_unique = df.drop_duplicates(subset=['hash'], keep='first')

    df_unique['label'] = df_unique['filepath'].apply(lambda x: x.split('/')[-2])
    df_unique['class'] = df_unique['filename'].apply(lambda x: 'train' if x[:2] == 'Tr' else 'test')

    # Copy unique files to new directory
    for filepath in tqdm(df_unique['filepath']):
        filename = os.path.basename(filepath)
        shutil.copy2(filepath, os.path.join(new_path, filename))

    root_dir = '/tmp/brain_tumor_dataset'
    os.makedirs(root_dir, exist_ok=True)

    # Create directories and copy files
    for _, row in df_unique.iterrows():
        class_dir = os.path.join(root_dir, row['class'])
        os.makedirs(class_dir, exist_ok=True)
        shutil.copy2(row['filepath'], os.path.join(class_dir, row['filename']))

    train_dir = os.path.join(root_dir, 'train')
    test_dir = os.path.join(root_dir, 'test')
    os.makedirs(train_dir, exist_ok=True)
    os.makedirs(test_dir, exist_ok=True)

    train_class_dir = os.path.join(train_dir, 'images')
    test_class_dir = os.path.join(test_dir, 'images')
    os.makedirs(train_class_dir, exist_ok=True)
    os.makedirs(test_class_dir, exist_ok=True)

    # Copy files to respective directories
    for _, row in df_unique.iterrows():
        target_dir = train_class_dir if row['class'] == 'train' else test_class_dir
        shutil.copy2(row['filepath'], os.path.join(target_dir, row['filename']))

    if vision_transformer:
        transform = get_vision_transform()
    else:
        transform = get_transform()

    # Create ImageFolder datasets
    train_set = torchvision.datasets.ImageFolder(root=train_dir, transform=transform)
    test_set = torchvision.datasets.ImageFolder(root=test_dir, transform=transform)

    # Check the contents of train_set.samples and test_set.samples
    print(f"Initial number of samples in train set: {len(train_set.samples)}")
    print(f"Initial number of samples in test set: {len(test_set.samples)}")

    # Create a filename-to-label dictionary
    file_to_label_train = dict(zip(df_unique[df_unique['class'] == 'train']['filename'],
                                   df_unique[df_unique['class'] == 'train']['label']))
    file_to_label_test = dict(zip(df_unique[df_unique['class'] == 'test']['filename'],
                                  df_unique[df_unique['class'] == 'test']['label']))

    # Override the labels with error handling
    train_samples = []
    for path, _ in train_set.samples:
        filename = os.path.basename(path)
        if filename in file_to_label_train:
            try:
                label = file_to_label_train[filename]
                train_samples.append((path, label_conversion_dict[label]))
            except KeyError as e:
                print(f"KeyError: {e} for file {path}. Skipping this file.")
                continue
        # else:
        #     print(f"Filename {filename} not found in file_to_label_train. Skipping file {path}.")
        #     continue

    # Verify if there are valid entries in train_samples
    print(f"Total samples in train set after overriding labels: {len(train_samples)}")

    train_set.samples = train_samples  # Update the train set with the new samples
    train_set.targets = [s[1] for s in train_set.samples]

    test_samples = []
    for path, _ in test_set.samples:
        filename = os.path.basename(path)
        if filename in file_to_label_test:
            try:
                label = file_to_label_test[filename]
                test_samples.append((path, label_conversion_dict[label]))
            except KeyError as e:
                print(f"KeyError: {e} for file {path}. Skipping this file.")
                continue
        # else:
        #     print(f"Filename {filename} not found in file_to_label_test. Skipping file {path}.")
        #     continue

    # Verify if there are valid entries in test_samples
    print(f"Total samples in test set after overriding labels: {len(test_samples)}")

    test_set.samples = test_samples  # Update the test set with the new samples
    test_set.targets = [s[1] for s in test_set.samples]

    # Verify total files and target values
    print(f"Total files in train set: {len(train_set)}, with target values: {list(set(train_set.targets))}")
    print(f"Total files in test set: {len(test_set)}, with target values: {list(set(test_set.targets))}")

    return train_set, test_set, label_conversion_dict


def data_loader(train_set, test_set, batch_size = 64):

    batch_size = batch_size

    # Create data loaders
    train_loader = DataLoader(
            train_set,
            batch_size=batch_size,
            shuffle=True,
            num_workers=2,
            pin_memory=True
        )
    test_loader = DataLoader(
            test_set,
            batch_size=batch_size,
            shuffle=False,
            num_workers=2,
            pin_memory=True
        )

    return train_loader, test_loader



def display_sample(train_set):

    # Randomly sample from dataset
    sample_indices = random.sample(range(len(train_set)), 9)

    # Plot examples
    fig, axes = plt.subplots(3, 3, figsize=(4, 4))
    for ax, idx in zip(axes.flatten(), sample_indices):
        img, label = train_set[idx]
        img_np = np.array(img)
        ax.imshow(img_np.squeeze(), cmap='gray')
        ax.set_title(f"Label: {label_conversion_dict[label]}", fontsize=8)
        ax.axis('off')
    plt.tight_layout()
    plt.show()


def get_transform():
    """
    Get the transformation pipeline for training data.

    Returns:
        transforms.Compose: Composition of transforms
    """
    return transforms.Compose([
    transforms.Grayscale(num_output_channels=1),  # Convert to greyscale (i.e., single channel)
    transforms.Resize((128,128)),                 # Resize images to 128x128 pixels
    transforms.ToTensor(),                        # Convert images to PyTorch tensors
    transforms.Normalize(mean=[0.5], std=[0.5])   # Normalize pixel values
    ])

def get_vision_transform():
    """
    Get the transformation pipeline for training data for the Vision Transformers.

    Returns:
        transforms.Compose: Composition of transforms
    """
    return transforms.Compose([
    transforms.Grayscale(num_output_channels=3),  # Convert grayscale images to 3-channel RGB (required by ViT)
    transforms.Resize((224, 224)),  # Resize all images to 224x224 pixels
    transforms.ToTensor(),  # Convert image to a tensor with values in [0, 1]
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values to [-1, 1]
    ])

# Define the function that produces Persistent Images from images
pers_imager = pimg.PersistenceImager()

def extract_topo_features(image):
    """Input: image (1, 128, 128) tensor â†’ Output: (5, 5) numpy array"""
    X = image.cpu().numpy().squeeze(0)
    rips = gd.RipsComplex(points = X, max_edge_length = 5)
    st = rips.create_simplex_tree(max_dimension=2)
    barcodes = st.persistence(homology_coeff_field = 2)
    barcodes_0 = st.persistence_intervals_in_dimension(0)
    barcodes_1 = st.persistence_intervals_in_dimension(1)
    pers_img_0 = pers_imager.transform(barcodes_0)
    pers_img_1 = pers_imager.transform(barcodes_1)

    return pers_img_1

class ImageTopoDataset(Dataset):
    def __init__(self, original_dataset, topo_data):
        self.original_dataset = original_dataset  # Your MNIST-like dataset
        self.topo_data = topo_data  # Precomputed features [N, 25]

    def __len__(self):
        return len(self.original_dataset)

    def __getitem__(self, idx):
        image, label = self.original_dataset[idx]
        return image, self.topo_data[idx], label  # (image, topo_data, label)


def add_topo_features(train_set, test_set):
    """
    Adds topological features to train and test datasets.

    Args:
        train_set: Training dataset
        test_set: Test dataset

    Returns:
        Tuple of (train_set_with_topo, test_set_with_topo)
    """
    # Initialize storage for topological features
    topo_data = {}

    # Process both datasets
    for dataset, name in [(train_set, 'train'), (test_set, 'test')]:
      topo_data[name] = []

      for i in range(len(dataset)):
        image, label = dataset[i]  # Get image (1, 128, 128)
        topo_features = extract_topo_features(image)  # Compute (5, 5) array
        topo_data[name].append(topo_features)

      # Convert to tensor and reshape to [N, 25] (since 5x5=25)
      topo_data[name] = torch.tensor(np.array(topo_data[name]), dtype=torch.float32).reshape(-1, 25)

    train_set = ImageTopoDataset(train_set, topo_data['train'])  # Wrap original dataset
    test_set = ImageTopoDataset(test_set, topo_data['test'])

    return train_set, test_set

