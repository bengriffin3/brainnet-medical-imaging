{"cells":[{"cell_type":"markdown","metadata":{"id":"ln5PIyQWEIwW"},"source":["# Brain Tumor Classification - Model Comparison\n","\n","This notebook compares the baseline model explored in the previous section with more advanced models including using residual connections, and using Vision Transformers.\n","\n","## 1. Setup and Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"qdjw98_exHCe","executionInfo":{"status":"ok","timestamp":1745610155726,"user_tz":300,"elapsed":4895,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"outputs":[],"source":["#!/usr/bin/env python\n","# coding: utf-8\n","import os\n","import pickle\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.optim import Adam\n","import matplotlib.pyplot as plt\n","import timm\n","import time\n","from torchsummary import summary"]},{"cell_type":"code","source":["# Topology imports\n","\n","!pip install gudhi --quiet\n","!pip install PersistenceImages --quiet\n","import gudhi as gd\n","import PersistenceImages.persistence_images as pimg"],"metadata":{"id":"elossVyFCv-c","executionInfo":{"status":"ok","timestamp":1745610160532,"user_tz":300,"elapsed":4804,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_rOrgDXSHAxv","outputId":"6b843f16-06a9-4c60-cb71-5e8cd07028de","executionInfo":{"status":"ok","timestamp":1745610163209,"user_tz":300,"elapsed":2676,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# # import our own modules (if run locally)\n","# import sys\n","# sys.path.append('../src')  # Add the src directory to the Python path\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Use os.path.join to avoid manual path issues\n","#path = os.path.join('gdrive', 'My Drive', 'Erdos', 'brainnet-medical-imaging', 'src')\n","os.chdir('/content/drive/My Drive/Deep Learning/BrainNet-Medical Imaging/src')\n","\n","# Change directory\n","# os.getcwd()\n","#os.chdir(path)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wlGEC4ZtEIwY","outputId":"3c94655d-c488-4930-ec69-eac4ede6128a","executionInfo":{"status":"ok","timestamp":1745610164218,"user_tz":300,"elapsed":1008,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Using device: cuda\n","Using device: cuda\n"]}],"source":["# import data\n","from config.data import data_setup, data_loader, add_topo_features\n","from models.vision_transformer import run_training\n","from utils.prediction import analyze_predictions, train_model\n","from models.cnn import BrainTumorCNN, BrainTumorCNN_RN, BrainTumorCNN_Topo\n","from utils.visualization import plot_epoch_times, plot_accuracy_results\n","\n","# Set random seeds for reproducibility\n","torch.manual_seed(42)\n","np.random.seed(42)\n","\n","# Set up device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"markdown","metadata":{"id":"JBEPm3IDEIwY"},"source":["## 2. Data Loading and Preprocessing"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7XrkFAsKEIwY","outputId":"b6ebed3c-7f1b-42e3-cbb1-848ad557a736","executionInfo":{"status":"ok","timestamp":1745610184785,"user_tz":300,"elapsed":20563,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/Deep Learning/BrainNet-Medical Imaging/src/config/data.py:87: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_unique['label'] = df_unique['filepath'].apply(lambda x: x.split('/')[-2])\n","/content/drive/My Drive/Deep Learning/BrainNet-Medical Imaging/src/config/data.py:88: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_unique['class'] = df_unique['filename'].apply(lambda x: 'train' if x[:2] == 'Tr' else 'test')\n","100%|██████████| 6726/6726 [00:03<00:00, 1705.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Initial number of samples in train set: 5521\n","Initial number of samples in test set: 1205\n","Total samples in train set after overriding labels: 5521\n","Total samples in test set after overriding labels: 1205\n","Total files in train set: 5521, with target values: [0, 1, 2, 3]\n","Total files in test set: 1205, with target values: [0, 1, 2, 3]\n"]}],"source":["# Load data and data_loaders\n","train_set, test_set, label_conversion_dict = data_setup()\n","train_loader, test_loader = data_loader(train_set, test_set)\n","\n","# Extract the class labels from the dictionary keys\n","class_labels = list(label_conversion_dict.keys())[:4]"]},{"cell_type":"markdown","metadata":{"id":"7Ay_C7jxEIwY"},"source":["# 3. Model training"]},{"cell_type":"markdown","metadata":{"id":"ItflALgmEIwY"},"source":["We start with our baseline model"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPIGqTWCEIwZ","outputId":"a2b97594-3cfa-42f4-8acf-7cfecb466def","executionInfo":{"status":"ok","timestamp":1745610184899,"user_tz":300,"elapsed":121,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["BrainTumorCNN(\n","  (features): Sequential(\n","    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): LeakyReLU(negative_slope=0.01)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n","    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): LeakyReLU(negative_slope=0.01)\n","    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n","    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): LeakyReLU(negative_slope=0.01)\n","    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (12): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n","    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (14): LeakyReLU(negative_slope=0.01)\n","    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=2048, out_features=1024, bias=True)\n","    (2): LeakyReLU(negative_slope=0.01)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=1024, out_features=4, bias=True)\n","  )\n",")\n"]}],"source":["# Initialize model\n","model_cnn = BrainTumorCNN().to(device)\n","print(model_cnn)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rgZOEOhhJ7K2","outputId":"c168c339-ada0-4e03-9ad8-2a1268b6103b","executionInfo":{"status":"ok","timestamp":1745610272572,"user_tz":300,"elapsed":87672,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10:\n","Train Loss: 0.7075, Val Loss: 0.5481, Accuracy: 76.60%\n","Epoch 1 took 9.15 seconds\n","Epoch 2/10:\n","Train Loss: 0.4219, Val Loss: 0.3796, Accuracy: 84.81%\n","Epoch 2 took 8.81 seconds\n","Epoch 3/10:\n","Train Loss: 0.3339, Val Loss: 0.3690, Accuracy: 85.39%\n","Epoch 3 took 8.71 seconds\n","Epoch 4/10:\n","Train Loss: 0.2617, Val Loss: 0.3239, Accuracy: 86.56%\n","Epoch 4 took 8.76 seconds\n","Epoch 5/10:\n","Train Loss: 0.2084, Val Loss: 0.3074, Accuracy: 89.13%\n","Epoch 5 took 8.77 seconds\n","Epoch 6/10:\n","Train Loss: 0.1658, Val Loss: 0.3132, Accuracy: 87.80%\n","Epoch 6 took 8.68 seconds\n","Epoch 7/10:\n","Train Loss: 0.1536, Val Loss: 0.1837, Accuracy: 93.03%\n","Epoch 7 took 8.62 seconds\n","Epoch 8/10:\n","Train Loss: 0.0999, Val Loss: 0.2065, Accuracy: 92.12%\n","Epoch 8 took 8.72 seconds\n","Epoch 9/10:\n","Train Loss: 0.1096, Val Loss: 0.5257, Accuracy: 80.91%\n","Epoch 9 took 8.72 seconds\n","Epoch 10/10:\n","Train Loss: 0.0946, Val Loss: 0.2034, Accuracy: 93.44%\n","Epoch 10 took 8.66 seconds\n"]}],"source":["history = train_model(\n","    model=model_cnn,\n","    train_loader=train_loader,\n","    val_loader=test_loader,\n","    num_epochs=10\n",")\n","\n","# Now you can access the following:\n","cnn_train_loss_list = history['train_loss_list']\n","cnn_test_loss_list = history['test_loss_list']\n","cnn_accuracy_list = history['accuracy_list']\n","cnn_all_predictions = history['all_predictions']\n","cnn_all_true_labels = history['all_true_labels']"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qK1FQfE5KBBZ","outputId":"40d704ca-a20b-403c-d64e-64e32c9d1d31","executionInfo":{"status":"ok","timestamp":1745610272579,"user_tz":300,"elapsed":3,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["CNN mean epoch time: 8.76 seconds\n"]}],"source":["# Print the mean of the epoch times\n","cnn_epoch_times = history['epoch_times']\n","print(f\"CNN mean epoch time: {np.mean(cnn_epoch_times):.2f} seconds\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dICiROfNEIwZ","outputId":"31012ab3-01ba-46e2-dbb1-fec7ce3bf611","executionInfo":{"status":"ok","timestamp":1745610272615,"user_tz":300,"elapsed":34,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Prediction Counts: Counter({np.int64(3): 380, np.int64(0): 303, np.int64(1): 276, np.int64(2): 246})\n","Epoch 2 Prediction Counts: Counter({np.int64(2): 338, np.int64(1): 310, np.int64(3): 293, np.int64(0): 264})\n","Epoch 3 Prediction Counts: Counter({np.int64(2): 369, np.int64(1): 317, np.int64(3): 272, np.int64(0): 247})\n","Epoch 4 Prediction Counts: Counter({np.int64(1): 372, np.int64(2): 336, np.int64(3): 294, np.int64(0): 203})\n","Epoch 5 Prediction Counts: Counter({np.int64(3): 347, np.int64(2): 334, np.int64(1): 268, np.int64(0): 256})\n","Epoch 6 Prediction Counts: Counter({np.int64(2): 354, np.int64(1): 327, np.int64(3): 276, np.int64(0): 248})\n","Epoch 7 Prediction Counts: Counter({np.int64(2): 335, np.int64(3): 312, np.int64(0): 281, np.int64(1): 277})\n","Epoch 8 Prediction Counts: Counter({np.int64(1): 337, np.int64(2): 330, np.int64(3): 304, np.int64(0): 234})\n","Epoch 9 Prediction Counts: Counter({np.int64(0): 397, np.int64(2): 324, np.int64(1): 291, np.int64(3): 193})\n","Epoch 10 Prediction Counts: Counter({np.int64(1): 332, np.int64(2): 331, np.int64(3): 297, np.int64(0): 245})\n","\n","Overall Prediction Counts Across All Epochs: Counter({np.int64(2): 3297, np.int64(1): 3107, np.int64(3): 2968, np.int64(0): 2678})\n","Overall Accuracy Across All Epochs: 86.98%\n","All results have been successfully saved in the 'results/' directory.\n"]}],"source":["# Analyse and save predictions\n","analyze_predictions(cnn_all_predictions, cnn_all_true_labels)\n","\n","# Create a directory called \"results\" if it doesn't already exist\n","os.makedirs('results', exist_ok=True)\n","\n","# Save the lists as numpy arrays for easy reloading\n","np.save('results/cnn_train_loss_list.npy', np.array(cnn_train_loss_list))\n","np.save('results/cnn_test_loss_list.npy', np.array(cnn_test_loss_list))\n","np.save('results/cnn_accuracy_list.npy', np.array(cnn_accuracy_list))\n","np.save('results/cnn_epoch_times_list.npy', np.array(cnn_epoch_times))\n","\n","# Save predictions and true labels as pickle files (more efficient for storing lists of lists)\n","with open('results/cnn_all_predictions.pkl', 'wb') as f:\n","    pickle.dump(cnn_all_predictions, f)\n","\n","with open('results/cnn_all_true_labels.pkl', 'wb') as f:\n","    pickle.dump(cnn_all_true_labels, f)\n","\n","print(\"All results have been successfully saved in the 'results/' directory.\")\n"]},{"cell_type":"markdown","metadata":{"id":"MiY-ELccEIwZ"},"source":["Now we try the same CNN but with residual connections."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zYD0W6jIEIwZ","outputId":"93719c2d-c306-4510-d83d-5002acaba0b1","executionInfo":{"status":"ok","timestamp":1745610272689,"user_tz":300,"elapsed":73,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["BrainTumorCNN_RN(\n","  (features): Sequential(\n","    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): LeakyReLU(negative_slope=0.01)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n","    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): LeakyReLU(negative_slope=0.01)\n","    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): ResidualBlock(\n","      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): ResidualBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=6272, out_features=1024, bias=True)\n","    (2): LeakyReLU(negative_slope=0.01)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=1024, out_features=4, bias=True)\n","  )\n",")\n"]}],"source":["model_cnn_res = BrainTumorCNN_RN().to(device)\n","print(model_cnn_res)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKUoa4dBKJvJ","outputId":"72e874ba-7e1f-4bb4-cf54-abbac4d25198","executionInfo":{"status":"ok","timestamp":1745610360534,"user_tz":300,"elapsed":87844,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10:\n","Train Loss: 0.8822, Val Loss: 0.5412, Accuracy: 77.26%\n","Epoch 1 took 8.76 seconds\n","Epoch 2/10:\n","Train Loss: 0.4153, Val Loss: 0.5060, Accuracy: 79.75%\n","Epoch 2 took 8.78 seconds\n","Epoch 3/10:\n","Train Loss: 0.3370, Val Loss: 0.4179, Accuracy: 82.90%\n","Epoch 3 took 8.83 seconds\n","Epoch 4/10:\n","Train Loss: 0.2902, Val Loss: 0.3450, Accuracy: 86.14%\n","Epoch 4 took 8.69 seconds\n","Epoch 5/10:\n","Train Loss: 0.2516, Val Loss: 0.4879, Accuracy: 82.16%\n","Epoch 5 took 8.84 seconds\n","Epoch 6/10:\n","Train Loss: 0.2125, Val Loss: 0.3687, Accuracy: 86.56%\n","Epoch 6 took 8.86 seconds\n","Epoch 7/10:\n","Train Loss: 0.1923, Val Loss: 0.2766, Accuracy: 87.80%\n","Epoch 7 took 8.81 seconds\n","Epoch 8/10:\n","Train Loss: 0.1801, Val Loss: 0.3020, Accuracy: 87.55%\n","Epoch 8 took 8.72 seconds\n","Epoch 9/10:\n","Train Loss: 0.1596, Val Loss: 0.1578, Accuracy: 93.78%\n","Epoch 9 took 8.75 seconds\n","Epoch 10/10:\n","Train Loss: 0.1141, Val Loss: 0.1421, Accuracy: 95.52%\n","Epoch 10 took 8.74 seconds\n"]}],"source":["history = train_model(\n","    model=model_cnn_res,\n","    train_loader=train_loader,\n","    val_loader=test_loader,\n","    num_epochs=10\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zqtSv7laKghg","outputId":"30c1de20-3b10-4f8d-a3f1-7c0ac8848eb4","executionInfo":{"status":"ok","timestamp":1745610360539,"user_tz":300,"elapsed":4,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["CNN (Res) mean epoch time: 8.78 seconds\n"]}],"source":["# Now you can access the following:\n","cnn_res_train_loss_list = history['train_loss_list']\n","cnn_res_test_loss_list = history['test_loss_list']\n","cnn_res_accuracy_list = history['accuracy_list']\n","cnn_res_all_predictions = history['all_predictions']\n","cnn_res_all_true_labels = history['all_true_labels']\n","\n","# Print the mean of the epoch times\n","cnn_res_epoch_times = history['epoch_times']\n","print(f\"CNN (Res) mean epoch time: {np.mean(cnn_res_epoch_times):.2f} seconds\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OZ8tWsrUEIwZ","outputId":"fdfae339-95be-453b-8623-c59124074052","executionInfo":{"status":"ok","timestamp":1745610360581,"user_tz":300,"elapsed":41,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Prediction Counts: Counter({np.int64(2): 386, np.int64(3): 288, np.int64(0): 277, np.int64(1): 254})\n","Epoch 2 Prediction Counts: Counter({np.int64(2): 417, np.int64(3): 328, np.int64(0): 281, np.int64(1): 179})\n","Epoch 3 Prediction Counts: Counter({np.int64(2): 389, np.int64(0): 316, np.int64(3): 277, np.int64(1): 223})\n","Epoch 4 Prediction Counts: Counter({np.int64(3): 349, np.int64(2): 326, np.int64(1): 305, np.int64(0): 225})\n","Epoch 5 Prediction Counts: Counter({np.int64(1): 450, np.int64(2): 310, np.int64(3): 306, np.int64(0): 139})\n","Epoch 6 Prediction Counts: Counter({np.int64(2): 394, np.int64(0): 330, np.int64(3): 288, np.int64(1): 193})\n","Epoch 7 Prediction Counts: Counter({np.int64(2): 384, np.int64(3): 291, np.int64(1): 270, np.int64(0): 260})\n","Epoch 8 Prediction Counts: Counter({np.int64(2): 364, np.int64(3): 327, np.int64(1): 297, np.int64(0): 217})\n","Epoch 9 Prediction Counts: Counter({np.int64(2): 330, np.int64(1): 301, np.int64(3): 295, np.int64(0): 279})\n","Epoch 10 Prediction Counts: Counter({np.int64(2): 322, np.int64(0): 297, np.int64(3): 296, np.int64(1): 290})\n","\n","Overall Prediction Counts Across All Epochs: Counter({np.int64(2): 3622, np.int64(3): 3045, np.int64(1): 2762, np.int64(0): 2621})\n","Overall Accuracy Across All Epochs: 85.94%\n","All results have been successfully saved in the 'results/' directory.\n"]}],"source":["# Analyse and save predictions\n","analyze_predictions(cnn_res_all_predictions, cnn_res_all_true_labels)\n","\n","# Create a directory called \"results\" if it doesn't already exist\n","os.makedirs('results', exist_ok=True)\n","\n","# Save the lists as numpy arrays for easy reloading\n","np.save('results/cnn_res_train_loss_list.npy', np.array(cnn_res_train_loss_list))\n","np.save('results/cnn_res_test_loss_list.npy', np.array(cnn_res_test_loss_list))\n","np.save('results/cnn_res_accuracy_list.npy', np.array(cnn_res_accuracy_list))\n","np.save('results/cnn_res_epoch_times_list.npy', np.array(cnn_res_epoch_times))\n","\n","# Save predictions and true labels as pickle files (more efficient for storing lists of lists)\n","with open('results/cnn_res_all_predictions.pkl', 'wb') as f:\n","    pickle.dump(cnn_res_all_predictions, f)\n","\n","with open('results/cnn_res_all_true_labels.pkl', 'wb') as f:\n","    pickle.dump(cnn_res_all_true_labels, f)\n","\n","print(\"All results have been successfully saved in the 'results/' directory.\")\n"]},{"cell_type":"markdown","source":["Now we try the same CNN but with topological features."],"metadata":{"id":"yfAz2leiT8FQ"}},{"cell_type":"code","source":["model_cnn_topo = BrainTumorCNN_Topo().to(device)\n","print(model_cnn_topo)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-5AtpuSTWMt5","executionInfo":{"status":"ok","timestamp":1745610360613,"user_tz":300,"elapsed":29,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}},"outputId":"1b53251a-aa07-4c3f-a7c7-ee891fb7119c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["BrainTumorCNN_Topo(\n","  (cnv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (cnv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n","  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (cnv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n","  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (cnv4): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n","  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (leakyRelu): LeakyReLU(negative_slope=0.01)\n","  (fc1): Linear(in_features=2073, out_features=1024, bias=True)\n","  (fc2): Linear(in_features=1024, out_features=4, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["train_set_topo, test_set_topo = add_topo_features(train_set,test_set) # takes a while to load topo data - around 10 minutes\n","train_loader_topo, test_loader_topo = data_loader(train_set_topo, test_set_topo)"],"metadata":{"id":"6AOZoExQuALP","executionInfo":{"status":"ok","timestamp":1745610924000,"user_tz":300,"elapsed":563386,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["history = train_model(\n","    model=model_cnn_topo,\n","    train_loader=train_loader_topo,\n","    val_loader=test_loader_topo,\n","    num_epochs=10\n",")"],"metadata":{"id":"uo4ZoapZWNsI","executionInfo":{"status":"ok","timestamp":1745611013200,"user_tz":300,"elapsed":89208,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e56b933e-e1f2-4b9f-c7c2-37d3f00fbad3"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10:\n","Train Loss: 0.9825, Val Loss: 0.7957, Accuracy: 67.97%\n","Epoch 1 took 9.04 seconds\n","Epoch 2/10:\n","Train Loss: 0.5507, Val Loss: 0.5631, Accuracy: 78.76%\n","Epoch 2 took 8.85 seconds\n","Epoch 3/10:\n","Train Loss: 0.3520, Val Loss: 0.3938, Accuracy: 84.15%\n","Epoch 3 took 8.82 seconds\n","Epoch 4/10:\n","Train Loss: 0.2608, Val Loss: 0.2757, Accuracy: 88.96%\n","Epoch 4 took 8.94 seconds\n","Epoch 5/10:\n","Train Loss: 0.1813, Val Loss: 0.3413, Accuracy: 87.05%\n","Epoch 5 took 8.98 seconds\n","Epoch 6/10:\n","Train Loss: 0.1505, Val Loss: 0.1727, Accuracy: 94.19%\n","Epoch 6 took 8.81 seconds\n","Epoch 7/10:\n","Train Loss: 0.0975, Val Loss: 0.2728, Accuracy: 90.62%\n","Epoch 7 took 8.92 seconds\n","Epoch 8/10:\n","Train Loss: 0.0812, Val Loss: 0.1349, Accuracy: 95.19%\n","Epoch 8 took 8.95 seconds\n","Epoch 9/10:\n","Train Loss: 0.0641, Val Loss: 0.1649, Accuracy: 94.85%\n","Epoch 9 took 8.97 seconds\n","Epoch 10/10:\n","Train Loss: 0.0421, Val Loss: 0.1468, Accuracy: 95.44%\n","Epoch 10 took 8.85 seconds\n"]}]},{"cell_type":"code","source":["# Now you can access the following:\n","cnn_topo_train_loss_list = history['train_loss_list']\n","cnn_topo_test_loss_list = history['test_loss_list']\n","cnn_topo_accuracy_list = history['accuracy_list']\n","cnn_topo_all_predictions = history['all_predictions']\n","cnn_topo_all_true_labels = history['all_true_labels']\n","\n","# Print the mean of the epoch times\n","cnn_topo_epoch_times = history['epoch_times']\n","print(f\"CNN (Topo) mean epoch time: {np.mean(cnn_topo_epoch_times):.2f} seconds\")"],"metadata":{"id":"yGTezu_AWFQM","executionInfo":{"status":"ok","timestamp":1745611013206,"user_tz":300,"elapsed":4,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ecfb5d7-18b0-4dfd-845e-1737112c88a6"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["CNN (Topo) mean epoch time: 8.91 seconds\n"]}]},{"cell_type":"code","source":["# Analyse and save predictions\n","analyze_predictions(cnn_topo_all_predictions, cnn_topo_all_true_labels)\n","\n","# Create a directory called \"results\" if it doesn't already exist\n","os.makedirs('results', exist_ok=True)\n","\n","# Save the lists as numpy arrays for easy reloading\n","np.save('results/cnn_topo_train_loss_list.npy', np.array(cnn_topo_train_loss_list))\n","np.save('results/cnn_topo_test_loss_list.npy', np.array(cnn_topo_test_loss_list))\n","np.save('results/cnn_topo_accuracy_list.npy', np.array(cnn_topo_accuracy_list))\n","np.save('results/cnn_topo_epoch_times_list.npy', np.array(cnn_topo_epoch_times))\n","\n","# Save predictions and true labels as pickle files (more efficient for storing lists of lists)\n","with open('results/cnn_topo_all_predictions.pkl', 'wb') as f:\n","    pickle.dump(cnn_topo_all_predictions, f)\n","\n","with open('results/cnn_topo_all_true_labels.pkl', 'wb') as f:\n","    pickle.dump(cnn_topo_all_true_labels, f)\n","\n","print(\"All results have been successfully saved in the 'results/' directory.\")"],"metadata":{"id":"RBvsYDhNWkYE","executionInfo":{"status":"ok","timestamp":1745611013209,"user_tz":300,"elapsed":3,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"95ce2686-1c54-48a6-a10b-c460af1b6ea8"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Prediction Counts: Counter({np.int64(3): 396, np.int64(2): 376, np.int64(0): 238, np.int64(1): 195})\n","Epoch 2 Prediction Counts: Counter({np.int64(2): 372, np.int64(3): 331, np.int64(0): 259, np.int64(1): 243})\n","Epoch 3 Prediction Counts: Counter({np.int64(1): 366, np.int64(2): 321, np.int64(3): 306, np.int64(0): 212})\n","Epoch 4 Prediction Counts: Counter({np.int64(2): 328, np.int64(0): 326, np.int64(3): 312, np.int64(1): 239})\n","Epoch 5 Prediction Counts: Counter({np.int64(0): 389, np.int64(3): 302, np.int64(2): 295, np.int64(1): 219})\n","Epoch 6 Prediction Counts: Counter({np.int64(2): 315, np.int64(1): 313, np.int64(3): 293, np.int64(0): 284})\n","Epoch 7 Prediction Counts: Counter({np.int64(1): 340, np.int64(3): 321, np.int64(2): 313, np.int64(0): 231})\n","Epoch 8 Prediction Counts: Counter({np.int64(1): 314, np.int64(2): 302, np.int64(3): 300, np.int64(0): 289})\n","Epoch 9 Prediction Counts: Counter({np.int64(1): 314, np.int64(2): 311, np.int64(3): 304, np.int64(0): 276})\n","Epoch 10 Prediction Counts: Counter({np.int64(2): 321, np.int64(3): 305, np.int64(0): 291, np.int64(1): 288})\n","\n","Overall Prediction Counts Across All Epochs: Counter({np.int64(2): 3254, np.int64(3): 3170, np.int64(1): 2831, np.int64(0): 2795})\n","Overall Accuracy Across All Epochs: 87.72%\n","All results have been successfully saved in the 'results/' directory.\n"]}]},{"cell_type":"markdown","metadata":{"id":"VP8TUNr-iHEd"},"source":["We use a pre-trained ViT, else we would overfit the data since ViT need a lot of data and we only have a few thousand images"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"sAm8MDe1EIwZ","executionInfo":{"status":"ok","timestamp":1745611015220,"user_tz":300,"elapsed":2011,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a2bc7ed7-8941-4cc4-ef16-13c6b44a20dc"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["# Load a pre-trained Vision Transformer model\n","vit_model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=4)  # Adjust 'num_classes' to your task\n","vit_model.to(device)\n","vit_model.train()  # Set model to training mode\n","\n","# Print the model architecture\n","verbose = 0\n","if verbose:\n","  summary(vit_model, input_size=(3, 224, 224))"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"usGNJbTzEIwa","executionInfo":{"status":"ok","timestamp":1745611035342,"user_tz":300,"elapsed":20120,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bc77679e-9b08-4202-8ff9-3a47c16814a9"},"outputs":[{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/Deep Learning/BrainNet-Medical Imaging/src/config/data.py:87: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_unique['label'] = df_unique['filepath'].apply(lambda x: x.split('/')[-2])\n","/content/drive/My Drive/Deep Learning/BrainNet-Medical Imaging/src/config/data.py:88: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_unique['class'] = df_unique['filename'].apply(lambda x: 'train' if x[:2] == 'Tr' else 'test')\n","100%|██████████| 6726/6726 [00:03<00:00, 1743.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Initial number of samples in train set: 5521\n","Initial number of samples in test set: 1205\n","Total samples in train set after overriding labels: 5521\n","Total samples in test set after overriding labels: 1205\n","Total files in train set: 5521, with target values: [0, 1, 2, 3]\n","Total files in test set: 1205, with target values: [0, 1, 2, 3]\n"]}],"source":["train_set_vit, test_set_vit, label_conversion_dict = data_setup(vision_transformer=True)\n","train_loader_vit, test_loader_vit = data_loader(train_set_vit, test_set_vit)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"ImJXjlHE7DfM","executionInfo":{"status":"ok","timestamp":1745612813501,"user_tz":300,"elapsed":584415,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"12d39cf8-6067-4ab6-b4b0-d309da892a67"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 1.5703, Val Loss: 1.0820, Accuracy: 51.87%, Epoch Time: 171.97 seconds\n","Epoch [2/10], Train Loss: 1.0151, Val Loss: 0.9423, Accuracy: 58.76%, Epoch Time: 177.05 seconds\n","Epoch [3/10], Train Loss: 0.9087, Val Loss: 1.1178, Accuracy: 56.51%, Epoch Time: 178.25 seconds\n","Epoch [4/10], Train Loss: 0.7968, Val Loss: 1.1164, Accuracy: 53.86%, Epoch Time: 178.26 seconds\n","Epoch [5/10], Train Loss: 0.7028, Val Loss: 0.6636, Accuracy: 71.62%, Epoch Time: 178.62 seconds\n","Epoch [6/10], Train Loss: 0.5897, Val Loss: 0.7281, Accuracy: 69.46%, Epoch Time: 178.49 seconds\n","Epoch [7/10], Train Loss: 0.5570, Val Loss: 0.6280, Accuracy: 74.61%, Epoch Time: 178.58 seconds\n","Epoch [8/10], Train Loss: 0.5502, Val Loss: 0.6466, Accuracy: 72.70%, Epoch Time: 178.51 seconds\n","Epoch [9/10], Train Loss: 0.4626, Val Loss: 0.5368, Accuracy: 77.10%, Epoch Time: 178.52 seconds\n","Epoch [10/10], Train Loss: 0.4527, Val Loss: 0.6069, Accuracy: 78.34%, Epoch Time: 178.58 seconds\n","ViT mean epoch time: 177.68 seconds\n"]}],"source":["# Standard optimizer setup\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(vit_model.parameters(), lr=0.001)\n","\n","# Set number of epochs\n","num_epochs = 10\n","\n","# Run training\n","train_loss_list, test_loss_list, accuracy_list, vit_all_predictions, vit_all_true_labels, vit_epoch_times = run_training(\n","    vit_model, train_loader_vit, test_loader_vit, optimizer, None, criterion, num_epochs, device, fine_tuning=False\n",")\n","\n","# Print the mean epoch time\n","vit_mean_epoch_time = np.mean(vit_epoch_times)\n","print(f\"ViT mean epoch time: {vit_mean_epoch_time:.2f} seconds\")"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"g1WEpApxyakL","executionInfo":{"status":"ok","timestamp":1745612813570,"user_tz":300,"elapsed":63,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f05a5581-cb66-443c-901f-fd647b2985a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Prediction Counts: Counter({np.int64(3): 598, np.int64(2): 435, np.int64(0): 169, np.int64(1): 3})\n","Epoch 2 Prediction Counts: Counter({np.int64(1): 433, np.int64(2): 339, np.int64(0): 250, np.int64(3): 183})\n","Epoch 3 Prediction Counts: Counter({np.int64(0): 418, np.int64(2): 381, np.int64(1): 330, np.int64(3): 76})\n","Epoch 4 Prediction Counts: Counter({np.int64(0): 721, np.int64(2): 278, np.int64(3): 106, np.int64(1): 100})\n","Epoch 5 Prediction Counts: Counter({np.int64(1): 454, np.int64(2): 287, np.int64(0): 245, np.int64(3): 219})\n","Epoch 6 Prediction Counts: Counter({np.int64(0): 316, np.int64(1): 316, np.int64(3): 299, np.int64(2): 274})\n","Epoch 7 Prediction Counts: Counter({np.int64(2): 460, np.int64(3): 284, np.int64(0): 264, np.int64(1): 197})\n","Epoch 8 Prediction Counts: Counter({np.int64(2): 387, np.int64(3): 330, np.int64(1): 310, np.int64(0): 178})\n","Epoch 9 Prediction Counts: Counter({np.int64(3): 386, np.int64(2): 313, np.int64(1): 285, np.int64(0): 221})\n","Epoch 10 Prediction Counts: Counter({np.int64(3): 385, np.int64(1): 334, np.int64(2): 324, np.int64(0): 162})\n","\n","Overall Prediction Counts Across All Epochs: Counter({np.int64(2): 3478, np.int64(0): 2944, np.int64(3): 2866, np.int64(1): 2762})\n","Overall Accuracy Across All Epochs: 66.48%\n","All results have been successfully saved in the 'results/' directory.\n"]}],"source":["# Analyse and save predictions\n","analyze_predictions(vit_all_predictions, vit_all_true_labels)\n","\n","# Create a directory called \"results\" if it doesn't already exist\n","os.makedirs('results', exist_ok=True)\n","\n","# Save the lists as numpy arrays for easy reloading\n","np.save('results/vit_train_loss_list.npy', np.array(train_loss_list))\n","np.save('results/vit_test_loss_list.npy', np.array(test_loss_list))\n","np.save('results/vit_accuracy_list.npy', np.array(accuracy_list))\n","np.save('results/vit_epoch_times_list.npy', np.array(vit_epoch_times))\n","\n","# Save predictions and true labels as pickle files (more efficient for storing lists of lists)\n","with open('results/vit_all_predictions.pkl', 'wb') as f:\n","    pickle.dump(vit_all_predictions, f)\n","\n","with open('results/vit_all_true_labels.pkl', 'wb') as f:\n","    pickle.dump(vit_all_true_labels, f)\n","\n","print(\"All results have been successfully saved in the 'results/' directory.\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"33UnPnGqh2cc"},"source":["### Now we explore a second version of the ViT model where we unfreeze the last Transformation block.\n","\n","Key extras about this model\n"," - Pre-trained Model: Like the first model, this one starts with a pre-trained Vision Transformer, but only the last transformer block and the classification head are unfrozen.\n"," - Fine-tuning: The last transformer block (blocks.11) and the normalization layers are unfrozen. This allows the model to adjust the more complex representations in the deeper layers of the transformer to fit your specific task.\n"," - (There are 12 transformer blocks in total)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Uo4x4OEnJMBT","executionInfo":{"status":"ok","timestamp":1745612815387,"user_tz":300,"elapsed":1809,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"outputs":[],"source":["# # Load a pre-trained Vision Transformer model\n","vit_model_ft = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=4)  # Adjust 'num_classes' to your task\n","\n","# Fine-tuning setup (assuming you want to unfreeze specific layers)\n","for name, param in vit_model_ft.named_parameters():\n","    if 'blocks.11' in name or 'norm' in name or 'head' in name:\n","        param.requires_grad = True\n","    else:\n","        param.requires_grad = False\n","\n","# Add Dropout layer before final classification layer\n","vit_model_ft.head = nn.Sequential(\n","    nn.Dropout(p=0.5),\n","    nn.Linear(vit_model_ft.head.in_features, 4)\n",")\n","\n","vit_model_ft.to(device)\n","vit_model_ft.train()\n","\n","# Print the model architecture\n","verbose = 0\n","if verbose:\n","  summary(vit_model_ft, input_size=(3, 224, 224))"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"KdPRz3IFdk2d","executionInfo":{"status":"ok","timestamp":1745612815395,"user_tz":300,"elapsed":2,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"86b2bbe5-6073-4d91-e316-f6077abcfe4f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]}],"source":["# Optimizer setup with different learning rates for head and other layers\n","head_params = list(vit_model_ft.head.parameters())\n","other_params = [p for p in vit_model_ft.parameters() if p not in set(head_params)]\n","\n","optimizer = Adam([\n","    {'params': head_params, 'lr': 0.001},\n","    {'params': other_params, 'lr': 0.0001}\n","])\n","\n","# Scheduler setup if needed\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"_MG2EfbfLzBt","executionInfo":{"status":"ok","timestamp":1745614200543,"user_tz":300,"elapsed":1385146,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4808b555-3c61-4c0b-d3a3-77c555e7304f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.5354, Val Loss: 0.2955, Accuracy: 87.72%, Epoch Time: 138.76 seconds\n","Epoch [2/10], Train Loss: 0.1832, Val Loss: 0.1285, Accuracy: 95.52%, Epoch Time: 138.61 seconds\n","Epoch [3/10], Train Loss: 0.0933, Val Loss: 0.1050, Accuracy: 96.76%, Epoch Time: 138.79 seconds\n","Epoch [4/10], Train Loss: 0.0524, Val Loss: 0.1017, Accuracy: 96.76%, Epoch Time: 138.81 seconds\n","Epoch [5/10], Train Loss: 0.0275, Val Loss: 0.0751, Accuracy: 98.17%, Epoch Time: 138.61 seconds\n","Epoch [6/10], Train Loss: 0.0165, Val Loss: 0.0849, Accuracy: 97.84%, Epoch Time: 138.60 seconds\n","Epoch [7/10], Train Loss: 0.0141, Val Loss: 0.0796, Accuracy: 98.26%, Epoch Time: 138.65 seconds\n","Epoch [8/10], Train Loss: 0.0201, Val Loss: 0.1664, Accuracy: 96.27%, Epoch Time: 138.51 seconds\n","Epoch [9/10], Train Loss: 0.0180, Val Loss: 0.1656, Accuracy: 96.60%, Epoch Time: 138.47 seconds\n","Epoch [10/10], Train Loss: 0.0068, Val Loss: 0.0996, Accuracy: 98.42%, Epoch Time: 138.55 seconds\n","ViT (fine-tuned) epoch time: 138.64 seconds\n"]}],"source":["# Run training\n","vit_ft_train_loss_list, vit_ft_test_loss_list, vit_ft_accuracy_list, vit_ft_all_predictions, vit_ft_all_true_labels, vit_ft_epoch_times = run_training(\n","    vit_model_ft, train_loader_vit, test_loader_vit, optimizer, scheduler, criterion, num_epochs, device, fine_tuning=True\n",")\n","\n","# Print the mean epoch time\n","vit_ft_mean_epoch_time = np.mean(vit_ft_epoch_times)\n","print(f\"ViT (fine-tuned) epoch time: {vit_ft_mean_epoch_time:.2f} seconds\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"doj22Xq6TEdi"},"outputs":[],"source":["# Analyse and save results\n","analyze_predictions(vit_ft_all_predictions, vit_ft_all_true_labels)\n","\n","# Save the lists as numpy arrays for easy reloading\n","np.save('results/vit_ft_train_loss_list.npy', np.array(vit_ft_train_loss_list))\n","np.save('results/vit_ft_test_loss_list.npy', np.array(vit_ft_test_loss_list))\n","np.save('results/vit_ft_accuracy_list.npy', np.array(vit_ft_accuracy_list))\n","np.save('results/vit_ft_epoch_times_list.npy', np.array(vit_ft_epoch_times))\n","\n","# Save predictions and true labels as pickle files (more efficient for storing lists of lists)\n","with open('results/vit_ft_all_predictions.pkl', 'wb') as f:\n","    pickle.dump(vit_ft_all_predictions, f)\n","\n","with open('results/vit_ft_all_true_labels.pkl', 'wb') as f:\n","    pickle.dump(vit_ft_all_true_labels, f)\n","\n","print(\"All fine-tuned results have been successfully saved in the 'results/' directory.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mAOn4hFMPehx"},"outputs":[],"source":["!ls 'results/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i9omKb0MN11y"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Load the results\n","cnn_train_loss = np.load('results/cnn_train_loss_list.npy')\n","cnn_test_loss = np.load('results/cnn_test_loss_list.npy')\n","cnn_accuracy = np.load('results/cnn_accuracy_list.npy')\n","\n","cnn_res_train_loss = np.load('results/cnn_res_train_loss_list.npy')\n","cnn_res_test_loss = np.load('results/cnn_res_test_loss_list.npy')\n","cnn_res_accuracy = np.load('results/cnn_res_accuracy_list.npy')\n","\n","cnn_topo_train_lost = np.load('results/cnn_topo_train_loss_list.npy')\n","cnn_topo_test_loss = np.load('results/cnn_topo_test_loss_list.npy')\n","cnn_topo_accuracy = np.load('results/cnn_topo_accuracy_list.npy')\n","\n","vit_train_loss = np.load('results/vit_train_loss_list.npy')\n","vit_test_loss = np.load('results/vit_test_loss_list.npy')\n","vit_accuracy = np.load('results/vit_accuracy_list.npy')\n","\n","vit_ft_train_loss = np.load('results/vit_ft_train_loss_list.npy')\n","vit_ft_test_loss = np.load('results/vit_ft_test_loss_list.npy')\n","vit_ft_accuracy = np.load('results/vit_ft_accuracy_list.npy')\n","\n","# Figure 1: Plot only CNN\n","fig1, (ax1_1, ax2_1) = plt.subplots(1, 2, figsize=(7, 4))  # Smaller figure size\n","plot_accuracy_results(cnn_train_loss, cnn_test_loss, cnn_accuracy, \"CNN\", ax1_1, ax2_1)\n","plt.tight_layout()\n","plt.show()\n","\n","# Figure 2: Plot CNN and CNN with Residual Blocks\n","fig2, (ax1_2, ax2_2) = plt.subplots(1, 2, figsize=(7, 4))\n","plot_accuracy_results(cnn_train_loss, cnn_test_loss, cnn_accuracy, \"CNN\", ax1_2, ax2_2)\n","plot_accuracy_results(cnn_res_train_loss, cnn_res_test_loss, cnn_res_accuracy, \"CNN Res\", ax1_2, ax2_2)\n","plt.tight_layout()\n","plt.show()\n","\n","# Figure 3: Plot CNN, CNN with Residual Blocks, and CNN_Topo\n","fig3, (ax1_3, ax2_3) = plt.subplots(1, 2, figsize=(7, 4))\n","plot_accuracy_results(cnn_train_loss, cnn_test_loss, cnn_accuracy, \"CNN\", ax1_3, ax2_3)\n","plot_accuracy_results(cnn_res_train_loss, cnn_res_test_loss, cnn_res_accuracy, \"CNN Res\", ax1_3, ax2_3)\n","plot_accuracy_results(cnn_topo_train_loss, cnn_topo_test_loss, cnn_topo_accuracy, \"CNN Topo\", ax1_3, ax2_3)\n","plt.tight_layout()\n","plt.show()\n","\n","# Figure 4: Plot CNN, CNN with Residual Blocks, CNN_Topo and ViT\n","fig4, (ax1_4, ax2_4) = plt.subplots(1, 2, figsize=(7, 4))\n","plot_accuracy_results(cnn_train_loss, cnn_test_loss, cnn_accuracy, \"CNN\", ax1_4, ax2_4)\n","plot_accuracy_results(cnn_res_train_loss, cnn_res_test_loss, cnn_res_accuracy, \"CNN Res\", ax1_4, ax2_4)\n","plot_accuracy_results(cnn_topo_train_loss, cnn_topo_test_loss, cnn_topo_accuracy, \"CNN Topo\", ax1_4, ax2_4)\n","plot_accuracy_results(vit_train_loss, vit_test_loss, vit_accuracy, \"ViT\", ax1_4, ax2_4)\n","plt.tight_layout()\n","plt.show()\n","\n","# Figure 5: Plot CNN, CNN with Residual Blocks, CNN_Topo ViT, and Fine-tuned ViT\n","fig5, (ax1_5, ax2_5) = plt.subplots(1, 2, figsize=(7, 4))\n","plot_accuracy_results(cnn_train_loss, cnn_test_loss, cnn_accuracy, \"CNN\", ax1_5, ax2_5)\n","plot_accuracy_results(cnn_res_train_loss, cnn_res_test_loss, cnn_res_accuracy, \"CNN Res\", ax1_5, ax2_5)\n","plot_accuracy_results(cnn_topo_train_loss, cnn_topo_test_loss, cnn_topo_accuracy, \"CNN Topo\", ax1_5, ax2_5)\n","plot_accuracy_results(vit_train_loss, vit_test_loss, vit_accuracy, \"ViT\", ax1_5, ax2_5)\n","plot_accuracy_results(vit_ft_train_loss, vit_ft_test_loss, vit_ft_accuracy, \"Fine-tuned ViT\", ax1_5, ax2_5)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7LLUmFuUOHNE"},"outputs":[],"source":["# Load the epoch times for all models\n","cnn_epoch_times = np.load('results/cnn_epoch_times_list.npy')\n","cnn_res_epoch_times = np.load('results/cnn_res_epoch_times_list.npy')\n","cnn_topo_epoch_times = np.load('results/cnn_topo_epoch_times_list.npy')\n","vit_epoch_times = np.load('results/vit_epoch_times_list.npy')\n","vit_ft_epoch_times = np.load('results/vit_ft_epoch_times_list.npy')\n","\n","# Figure 1: Plot only CNN epoch times\n","fig1, ax1 = plt.subplots(figsize=(7, 4))  # Smaller figure size\n","plot_epoch_times(cnn_epoch_times, \"CNN\", ax1)\n","plt.tight_layout()\n","plt.show()\n","\n","# Figure 2: Plot CNN and CNN with Residual Blocks epoch times\n","fig2, ax2 = plt.subplots(figsize=(7, 4))\n","plot_epoch_times(cnn_epoch_times, \"CNN\", ax2)\n","plot_epoch_times(cnn_res_epoch_times, \"CNN Res\", ax2)\n","plt.tight_layout()\n","plt.show()\n","\n","# Figure 3: Plot CNN, CNN with Residual Blocks, and CNN_Topo\n","fig3, ax3 = plt.subplots(figsize=(7, 4))\n","plot_epoch_times(cnn_epoch_times, \"CNN\", ax3)\n","plot_epoch_times(cnn_res_epoch_times, \"CNN Res\", ax3)\n","plot_epoch_times(cnn_topo_epoch_times, \"CNN Topo\", ax3)\n","plt.tight_layout()\n","plt.show()\n","\n","# Figure 4: Plot CNN, CNN with Residual Blocks, CNN_Topo and ViT epoch times\n","fig4, ax4 = plt.subplots(figsize=(7, 4))\n","plot_epoch_times(cnn_epoch_times, \"CNN\", ax4)\n","plot_epoch_times(cnn_res_epoch_times, \"CNN Res\", ax4)\n","plot_epoch_times(cnn_topo_epoch_times, \"CNN Topo\", ax4)\n","plot_epoch_times(vit_epoch_times, \"ViT\", ax4)\n","plt.tight_layout()\n","plt.show()\n","\n","# Figure 5: Plot CNN, CNN with Residual Blocks, ViT, and Fine-tuned ViT epoch times\n","fig5, ax5 = plt.subplots(figsize=(7, 4))\n","plot_epoch_times(cnn_epoch_times, \"CNN\", ax5)\n","plot_epoch_times(cnn_res_epoch_times, \"CNN Res\", ax5)\n","plot_epoch_times(cnn_topo_epoch_times, \"CNN Topo\", ax5)\n","plot_epoch_times(vit_epoch_times, \"ViT\", ax5)\n","plot_epoch_times(vit_ft_epoch_times, \"Fine-tuned ViT\", ax5)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t3r7qw-efLqB","executionInfo":{"status":"aborted","timestamp":1745614201932,"user_tz":300,"elapsed":1,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"outputs":[],"source":["# If you want to download the results locally\n","\n","import shutil\n","from google.colab import files\n","\n","# Compress the 'results' folder into a zip file\n","shutil.make_archive('results', 'zip', 'results')\n","\n","# Create a download link for the zip file\n","files.download('results.zip')"]},{"cell_type":"code","source":[],"metadata":{"id":"KirljRd4XgLc","executionInfo":{"status":"aborted","timestamp":1745614201954,"user_tz":300,"elapsed":1,"user":{"displayName":"Feride Ceren Kose","userId":"16293362012996408332"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}